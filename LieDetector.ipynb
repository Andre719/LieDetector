{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Restart with command below if keras uses Theano backend\n",
    "# KERAS_BACKEND=tensorflow jupyter notebook --no-browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network \"works\" but is not accurate (not better than random)  \n",
    "### Things to try:  \n",
    "* use TensorBoard\n",
    "* play around with hyperparameters  \n",
    "* play around with layers  \n",
    "* play arond with hidden layer activations\n",
    "* frame augmentation  \n",
    "* manually adjust videos where subject is not centered  \n",
    "* get more data (videos) - only have 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, TimeDistributed, LSTM, Dropout, Lambda\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from PIL import Image\n",
    "import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VIDEO_FOLDER = (os.getcwd() + '/videos/Clips')\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 5\n",
    "FRAME_SQUARE_DIM = 178\n",
    "FRAMES_PER_VIDEO = 30\n",
    "DROP_PROB = 0.3\n",
    "LSTM_UNITS = 2048\n",
    "FIRST_DENSE_UNITS = 1024\n",
    "SECOND_DENSE_UNITS = 512\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model(frames_per_video, frame_square_dim, drop_prob, lstm_units, first_dense_units, second_dense_units):\n",
    "    # Video file placeholder. Shape = (# of frames, frame-width, frame-length, # of frame-channels (i.e. rgb))\n",
    "    video_input = Input(shape=(frames_per_video, frame_square_dim, frame_square_dim, 3), name='video_input')\n",
    "\n",
    "    # TRANSFER LEARNING LAYER\n",
    "    # Initialize CNN with weights from InceptionV3 trained on Imagenet.\n",
    "    IncV3 = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Freeze Inception layers, so we can use the already trained weights that represent lower level\n",
    "    # vision and pattern recognition.\n",
    "    IncV3.trainable = False\n",
    "    \n",
    "    # TIME DISTRIBUTION LAYER\n",
    "    # Run each frame through an InceptionV3 CNN layer.\n",
    "    encoded_frames = TimeDistributed(Lambda(lambda x: IncV3(x)), name='encoded_frames')(video_input)\n",
    "\n",
    "    # LSTM LAYER\n",
    "    # Run each frames CNN output through the LSTM layer.\n",
    "    encoded_vid = LSTM(units=lstm_units, dropout=drop_prob, name='encoded_vid')(encoded_frames)\n",
    "\n",
    "    # ADDITIONAL LAYERS TO TRAIN NEW CLASSES from our new video footage.\n",
    "    # Add fully-connected layers before predictions.\n",
    "    first_dense = Dense(units=first_dense_units, activation='relu', name='first_dense')(encoded_vid)\n",
    "    second_dense = Dense(units=second_dense_units, activation='relu', name='second_dense')(first_dense)\n",
    "\n",
    "    # Add a logistic layer with 2 new classes - \"Lying\" and \"Truth\".\n",
    "    predictions = Dense(1, activation='sigmoid', name='predictions')(second_dense)\n",
    "\n",
    "    # Throw it all into a Model object.\n",
    "    model = Model(inputs=[video_input], outputs=predictions)\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "video_input (InputLayer)     (None, 30, 178, 178, 3)   0         \n",
      "_________________________________________________________________\n",
      "encoded_frames (TimeDistribu (None, 30, 2048)          0         \n",
      "_________________________________________________________________\n",
      "encoded_vid (LSTM)           (None, 2048)              33562624  \n",
      "_________________________________________________________________\n",
      "first_dense (Dense)          (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "second_dense (Dense)         (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 36,186,113.0\n",
      "Trainable params: 36,186,113.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(FRAMES_PER_VIDEO, FRAME_SQUARE_DIM, DROP_PROB, LSTM_UNITS, FIRST_DENSE_UNITS, SECOND_DENSE_UNITS)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make Frames directories in Truthful and Deceptive folders\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Truthful/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Truthful/Frames')\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Deceptive/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Deceptive/Frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(frame, square_dim):\n",
    "    # get aspect ratio\n",
    "    aspect = frame.size[0]/frame.size[1]\n",
    "    \n",
    "    # resize to 178 on shortest side and keep original aspect ratio\n",
    "    frame = frame.resize((int(square_dim*aspect), square_dim))\n",
    "    \n",
    "    # crop 178 square from center\n",
    "    half_the_width = frame.size[0] / 2\n",
    "    half_the_height = frame.size[1] / 2\n",
    "    frame = frame.crop(\n",
    "        (\n",
    "            half_the_width - (square_dim/2),\n",
    "            half_the_height - (square_dim/2),\n",
    "            half_the_width + (square_dim/2),\n",
    "            half_the_height + (square_dim/2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_frames_from_videos(folder, frames_per_video, frame_square_dim):\n",
    "    \n",
    "    # get one video at a time in the folder\n",
    "    vid_counter = 0\n",
    "    for video_file in os.listdir(folder):\n",
    "        vid_counter += 1\n",
    "        \n",
    "        if video_file not in ['Frames']:\n",
    "            # printing status\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "            sys.stdout.write('Getting frames for video ' + str(vid_counter) + ' of ' + str(len(os.listdir(folder))))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            video = (folder + '/' + video_file)\n",
    "            video = imageio.get_reader(video,  'ffmpeg')\n",
    "\n",
    "            # get 30 evenly spaced frames per video\n",
    "            step = video.get_meta_data()['nframes'] / frames_per_video\n",
    "            frames_to_get = range(1, video.get_meta_data()['nframes'], int(step))\n",
    "            frames = []\n",
    "            for i in frames_to_get:\n",
    "                frames.append(i)\n",
    "\n",
    "            # only get first 30 frames if there are 31\n",
    "            frames = frames[:30]\n",
    "\n",
    "            # Resize, crop, and save each frame in the Frames folder\n",
    "            ## ex: (os.getcwd + '/videos/Clips/Truthful/Frames') for Truth videos\n",
    "            for frame in frames:\n",
    "                this_frame = video.get_data(frame)\n",
    "                imageio.imwrite(\"this_frame.jpg\", this_frame)\n",
    "                this_frame = Image.open(\"this_frame.jpg\")\n",
    "                this_frame = resize_and_crop(this_frame, frame_square_dim)\n",
    "                this_frame.save((folder + '/Frames/' + video_file + '_0' + str(frame) + '.jpg'))\n",
    "                \n",
    "    print('\\n')\n",
    "    print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data(folder, frames_per_video):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for vid_type in os.listdir(folder):\n",
    "        if not vid_type.startswith('.'):\n",
    "            if vid_type in ['Deceptive']:\n",
    "                label = 'Deceptive'\n",
    "            else:\n",
    "                label = 'Truthful'\n",
    "            \n",
    "            video_tensor = []\n",
    "            frame_counter = 1\n",
    "            frame_files = os.listdir(folder + '/' + vid_type + '/Frames')\n",
    "            for frame_file_iter in range(len(frame_files)):\n",
    "                if frame_file_iter == 0:\n",
    "                    continue\n",
    "                \n",
    "                frame = (folder + '/' + vid_type + '/Frames/' + frame_files[frame_file_iter])\n",
    "\n",
    "                frame = Image.open(frame)\n",
    "\n",
    "                frame_tensor = np.asarray(frame.convert('RGB'))\n",
    "                \n",
    "                video_tensor.append(frame_tensor)\n",
    "                \n",
    "                if frame_counter == frames_per_video:\n",
    "                    X.append(video_tensor)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    video_tensor = []\n",
    "                    frame_counter = 0\n",
    "                    \n",
    "                frame_counter += 1\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    print('Complete!')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting frames for video 2 of 62"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7107cac4c675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prepare video clips into a resized and cropped series of frames for each video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_frames_from_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Deceptive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRAMES_PER_VIDEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRAME_SQUARE_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-faaf9d495ff7>\u001b[0m in \u001b[0;36mget_frames_from_videos\u001b[0;34m(folder, frames_per_video, frame_square_dim)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m## ex: (os.getcwd + '/videos/Clips/Truthful/Frames') for Truth videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mthis_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this_frame.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mthis_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this_frame.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkClosed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BaseReaderWriter_last_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Image tests im and meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reinitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_skip_frames\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36m_read_frame_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_catcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_n_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;31m# Check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mread_n_bytes\u001b[0;34m(f, N)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mextra_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Deceptive'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!rames for video 61 of 61\n"
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Truthful'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Get video tensors ready for network input\n",
    "X, y = get_data(VIDEO_FOLDER, FRAMES_PER_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76 samples, validate on 19 samples\n",
      "Epoch 1/3\n",
      "76/76 [==============================] - 220s - loss: 7.2398 - acc: 0.5526 - val_loss: 11.0282 - val_acc: 0.3158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "76/76 [==============================] - 219s - loss: 7.2107 - acc: 0.5526 - val_loss: 11.0282 - val_acc: 0.3158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "76/76 [==============================] - 218s - loss: 7.2107 - acc: 0.5526 - val_loss: 11.0282 - val_acc: 0.3158\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the new video footage.\n",
    "#X_train = X_train.astype('float32')\n",
    "\n",
    "# fits the model on batches\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=TEST_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "#model.save_weights('binary_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc0859e550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Test on the out of sample (test) video footage.\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('Predicting on test data')\n",
    "y_pred = np.rint(model.predict(X_test))\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0]\n",
      " [12  0]]\n"
     ]
    }
   ],
   "source": [
    "# Show confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "0 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "1 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n",
      "1 : 0.0\n",
      "0 : 0.0\n"
     ]
    }
   ],
   "source": [
    "for test,pred in zip(y_test, y_pred):\n",
    "    print(str(test) + ' : ' + str(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
