{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restart with command below if keras uses Theano backend\n",
    "# KERAS_BACKEND=tensorflow jupyter notebook --no-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, TimeDistributed, LSTM, Dropout\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pylab\n",
    "from PIL import Image\n",
    "import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "VIDEO_FOLDER = (os.getcwd() + '/videos/Clips')\n",
    "BATCH_SIZE = 5\n",
    "FRAME_SQUARE_DIM = 178\n",
    "FRAMES_PER_VIDEO = 30\n",
    "KEEP_PROB = 1.0\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model(frames_per_video, frame_square_dim, keep_prob):\n",
    "    # Video file placeholder. Shape = (# of frames, frame-width, frame-length, # of frame-channels (i.e. rgb))\n",
    "    video_input = Input(shape=(frames_per_video, frame_square_dim, frame_square_dim, 3), name='video_input')\n",
    "\n",
    "    # TRANSFER LEARNING LAYER\n",
    "    # Initialize CNN with weights from InceptionV3 trained on Imagenet.\n",
    "    IncV3 = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Freeze Inception layers, so we can use the already trained weights that represent lower level\n",
    "    # vision and pattern recognition.\n",
    "    IncV3.trainable = False\n",
    "    \n",
    "    # TIME DISTRIBUTION LAYER\n",
    "    # Run each frame through an InceptionV3 CNN layer.\n",
    "    encoded_frames = TimeDistributed(IncV3, name='encoded_frames')(video_input)\n",
    "\n",
    "    # LSTM LAYER\n",
    "    # Run each frames CNN output through the LSTM layer.\n",
    "    encoded_vid = LSTM(256, name='encoded_vid')(encoded_frames)\n",
    "\n",
    "    # ADDITIONAL LAYERS TO TRAIN NEW CLASSES from our new video footage.\n",
    "    # Add a fully-connected layer with a dropout before predictions.\n",
    "    dense_relu = Dense(1024, activation='relu', name='dense_relu')(encoded_vid)\n",
    "    dense_dropout = Dropout(keep_prob, name='dense_dropout')(dense_relu)\n",
    "\n",
    "    # Add a logistic layer with 2 new classes - \"Lying\" and \"Truth\".\n",
    "    predictions = Dense(1, activation='sigmoid', name='predictions')(dense_dropout)\n",
    "\n",
    "    # Throw it all into a Model object.\n",
    "    model = Model(inputs=video_input, outputs=predictions)\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "video_input (InputLayer)     (None, 30, 178, 178, 3)   0         \n",
      "_________________________________________________________________\n",
      "encoded_frames (TimeDistribu (None, 30, 2048)          21802784  \n",
      "_________________________________________________________________\n",
      "encoded_vid (LSTM)           (None, 256)               2360320   \n",
      "_________________________________________________________________\n",
      "dense_relu (Dense)           (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_dropout (Dropout)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 24,427,297.0\n",
      "Trainable params: 2,624,513.0\n",
      "Non-trainable params: 21,802,784.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(FRAMES_PER_VIDEO, FRAME_SQUARE_DIM, KEEP_PROB)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make Frames directories in Truthful and Deceptive folders\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Truthful/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Truthful/Frames')\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Deceptive/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Deceptive/Frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(frame, square_dim):\n",
    "    # get aspect ratio\n",
    "    aspect = frame.size[0]/frame.size[1]\n",
    "    \n",
    "    # resize to 178 on shortest side and keep original aspect ratio\n",
    "    frame = frame.resize((int(square_dim*aspect), square_dim))\n",
    "    \n",
    "    # crop 178 square from center\n",
    "    half_the_width = frame.size[0] / 2\n",
    "    half_the_height = frame.size[1] / 2\n",
    "    frame = frame.crop(\n",
    "        (\n",
    "            half_the_width - (square_dim/2),\n",
    "            half_the_height - (square_dim/2),\n",
    "            half_the_width + (square_dim/2),\n",
    "            half_the_height + (square_dim/2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_frames_from_videos(folder, frames_per_video, frame_square_dim):\n",
    "    \n",
    "    # get one video at a time in the folder\n",
    "    vid_counter = 0\n",
    "    for video_file in os.listdir(folder):\n",
    "        vid_counter += 1\n",
    "        \n",
    "        if video_file not in ['Frames']:\n",
    "            # printing status\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "            sys.stdout.write('Getting frames for video ' + str(vid_counter) + ' of ' + str(len(os.listdir(folder))))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            video = (folder + '/' + video_file)\n",
    "            video = imageio.get_reader(video,  'ffmpeg')\n",
    "\n",
    "            # get 30 evenly spaced frames per video\n",
    "            step = video.get_meta_data()['nframes'] / frames_per_video\n",
    "            frames_to_get = range(1, video.get_meta_data()['nframes'], int(step))\n",
    "            frames = []\n",
    "            for i in frames_to_get:\n",
    "                frames.append(i)\n",
    "\n",
    "            # only get first 30 frames if there are 31\n",
    "            frames = frames[:30]\n",
    "\n",
    "            # Resize, crop, and save each frame in the Frames folder\n",
    "            ## ex: (os.getcwd + '/videos/Clips/Truthful/Frames') for Truth videos\n",
    "            for frame in frames:\n",
    "                this_frame = video.get_data(frame)\n",
    "                imageio.imwrite(\"this_frame.jpg\", this_frame)\n",
    "                this_frame = Image.open(\"this_frame.jpg\")\n",
    "                this_frame = resize_and_crop(this_frame, frame_square_dim)\n",
    "                this_frame.save((folder + '/Frames/' + video_file + '_0' + str(frame) + '.jpg'))\n",
    "                \n",
    "    print('\\n')\n",
    "    print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data(folder, frames_per_video):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for vid_type in os.listdir(folder):\n",
    "        if not vid_type.startswith('.'):\n",
    "            if vid_type in ['Deceptive']:\n",
    "                label = 'Deceptive'\n",
    "            else:\n",
    "                label = 'Truthful'\n",
    "            \n",
    "            video_tensor = []\n",
    "            frame_counter = 1\n",
    "            frame_files = os.listdir(folder + '/' + vid_type + '/Frames')\n",
    "            for frame_file_iter in range(len(frame_files)):\n",
    "                if frame_file_iter == 0:\n",
    "                    continue\n",
    "                \n",
    "                frame = (folder + '/' + vid_type + '/Frames/' + frame_files[frame_file_iter])\n",
    "\n",
    "                frame = Image.open(frame)\n",
    "\n",
    "                frame_tensor = np.asarray(frame.convert('RGB'))\n",
    "                \n",
    "                video_tensor.append(frame_tensor)\n",
    "                \n",
    "                if frame_counter == frames_per_video:\n",
    "                    X.append(video_tensor)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    video_tensor = []\n",
    "                    frame_counter = 0\n",
    "                    \n",
    "                frame_counter += 1\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    print('Complete!')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62 video files.\n",
      "Getting frames for video 62 of 62\r"
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Deceptive'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!rames for video 61 of 61\n"
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Truthful'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Get video tensors ready for network input\n",
    "X, y = get_data(VIDEO_FOLDER, FRAMES_PER_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76 samples, validate on 19 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the new video footage.\n",
    "#model = get_model(FRAMES_PER_VIDEO, FRAME_SQUARE_DIM, KEEP_PROB)\n",
    "#X_train = X_train.astype(float)\n",
    "\n",
    "# fits the model on batches\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=TEST_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "#model.save_weights('binary_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[17][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
