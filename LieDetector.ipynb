{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'imageio.plugins.ffmpeg' has no attribute 'download'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-09e92d87345b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'imageio.plugins.ffmpeg' has no attribute 'download'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, TimeDistributed, LSTM, GlobalAveragePooling2D, AveragePooling3D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pylab\n",
    "from PIL import Image\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VIDEO_FOLDER = (os.getcwd() + '/videos/Clips')\n",
    "BATCH_SIZE = 32\n",
    "FRAME_SQUARE_DIM = 178\n",
    "FRAMES_PER_VIDEO = 30\n",
    "KEEP_PROB = 0.7\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make Frames directories in Truthful and Deceptive folders\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Truthful/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Truthful/Frames')\n",
    "if not os.path.exists((VIDEO_FOLDER + '/Deceptive/Frames')):\n",
    "    os.mkdir(VIDEO_FOLDER + '/Deceptive/Frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(frame, square_dim):\n",
    "    # get aspect ratio\n",
    "    aspect = frame.size[0]/frame.size[1]\n",
    "    \n",
    "    # resize to 178 on shortest side and keep original aspect ratio\n",
    "    frame = frame.resize((int(square_dim*aspect), square_dim))\n",
    "    \n",
    "    # crop 178 square from center\n",
    "    half_the_width = frame.size[0] / 2\n",
    "    half_the_height = frame.size[1] / 2\n",
    "    frame = frame.crop(\n",
    "        (\n",
    "            half_the_width - (square_dim/2),\n",
    "            half_the_height - (square_dim/2),\n",
    "            half_the_width + (square_dim/2),\n",
    "            half_the_height + (square_dim/2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_frames_from_videos(folder, frames_per_video, frame_square_dim):\n",
    "    \n",
    "    # get one video at a time in the folder\n",
    "    vid_counter = 0\n",
    "    for video_file in os.listdir(folder):\n",
    "        vid_counter += 1\n",
    "        \n",
    "        if video_file not in ['Frames']:\n",
    "            # printing status\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "            sys.stdout.write('Getting frames for video ' + str(vid_counter) + ' of ' + str(len(os.listdir(folder))))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            video = (folder + '/' + video_file)\n",
    "            video = imageio.get_reader(video,  'ffmpeg')\n",
    "\n",
    "            # get 30 evenly spaced frames per video\n",
    "            step = video.get_meta_data()['nframes'] / frames_per_video\n",
    "            frames_to_get = range(1, video.get_meta_data()['nframes'], int(step))\n",
    "            frames = []\n",
    "            for i in frames_to_get:\n",
    "                frames.append(i)\n",
    "\n",
    "            # only get first 30 frames if there are 31\n",
    "            frames = frames[:30]\n",
    "\n",
    "            # Resize, crop, and save each frame in the Frames folder\n",
    "            ## ex: (os.getcwd + '/videos/Clips/Truthful/Frames') for Truth videos\n",
    "            for frame in frames:\n",
    "                this_frame = video.get_data(frame)\n",
    "                imageio.imwrite(\"this_frame.jpg\", this_frame)\n",
    "                this_frame = Image.open(\"this_frame.jpg\")\n",
    "                this_frame = resize_and_crop(this_frame, frame_square_dim)\n",
    "                this_frame.save((folder + '/Frames/' + video_file + '_0' + str(frame) + '.jpg'))\n",
    "                \n",
    "    print('\\n')\n",
    "    print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data(folder, frames_per_video):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for vid_type in os.listdir(folder):\n",
    "        if not vid_type.startswith('.'):\n",
    "            if vid_type in ['Deceptive']:\n",
    "                label = 'Deceptive'\n",
    "            else:\n",
    "                label = 'Truthful'\n",
    "            \n",
    "            video_tensor = []\n",
    "            frame_counter = 1\n",
    "            frame_files = os.listdir(folder + '/' + vid_type + '/Frames')\n",
    "            for frame_file_iter in range(len(frame_files)):\n",
    "                if frame_file_iter == 0:\n",
    "                    continue\n",
    "                \n",
    "                frame = (folder + '/' + vid_type + '/Frames/' + frame_files[frame_file_iter])\n",
    "\n",
    "                frame = Image.open(frame)\n",
    "\n",
    "                frame_tensor = np.asarray(frame.convert('RGB'))\n",
    "                \n",
    "                video_tensor.append(frame_tensor)\n",
    "                \n",
    "                if frame_counter == frames_per_video:\n",
    "                    X.append(video_tensor)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    video_tensor = []\n",
    "                    frame_counter = 0\n",
    "                    \n",
    "                frame_counter += 1\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    print('Complete!')\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62 video files.\n",
      "Getting frames for video 62 of 62\r"
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Deceptive'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!rames for video 61 of 61\n"
     ]
    }
   ],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos((VIDEO_FOLDER + '/Truthful'), FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Get video tensors ready for network input\n",
    "X, y = get_data(VIDEO_FOLDER, FRAMES_PER_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# NEXT IS TO TEST NN\n",
    "# AND THEN TRY IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model(frames_per_video, frame_square_dim, keep_prob):\n",
    "    # Video file placeholder. Shape = (# of frames, frame-width, frame-length, # of frame-channels (i.e. rgb))\n",
    "    video = Input(shape=(frames_per_video, frame_square_dim, frame_square_dim, 3))\n",
    "\n",
    "    # TRANSFER LEARNING LAYER\n",
    "    # Initialize CNN with weights from InceptionV3 trained on Imagenet.\n",
    "    IncV3 = InceptionV3(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # add a global spatial average pooling layer\n",
    "    #x = IncV3.output\n",
    "    #x = AveragePooling3D()(x)\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # TIME DISTRIBUTION LAYER\n",
    "    # Run each frame through an InceptionV3 CNN layer.\n",
    "    encoded_frames = TimeDistributed(IncV3)(video)\n",
    "\n",
    "    # LSTM LAYER\n",
    "    # Run each frames CNN output through the LSTM layer.\n",
    "    encoded_vid = LSTM(256)(encoded_frames)\n",
    "\n",
    "    # ADDITIONAL LAYERS TO TRAIN NEW CLASSES from our new video footage.\n",
    "    # Add a fully-connected layer with a dropout before predictions.\n",
    "    x = Dense(1024, activation='relu')(encoded_vid)\n",
    "    x = Dropout(keep_prob)(x)\n",
    "\n",
    "    # Add a logistic layer with 2 new classes - \"Lying\" and \"Truth\".\n",
    "    predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    # Throw it all into a Model object.\n",
    "    model = Model(input=IncV3.input, output=predictions)\n",
    "\n",
    "    # Freeze convolutional InceptionV3 layers because we want to start with the it's pre-trained weights.\n",
    "    # This is the \"learning\" that's being \"transferred\".\n",
    "    for layer in IncV3.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_3: expected ndim=3, found ndim=5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c4c7f2cce699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRAMES_PER_VIDEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFRAME_SQUARE_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEEP_PROB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-b9bd2fa8f551>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(frames_per_video, frame_square_dim, keep_prob)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LSTM LAYER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Run each frames CNN output through the LSTM layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mencoded_vid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# ADDITIONAL LAYERS TO TRAIN NEW CLASSES from our new video footage.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    467\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                                          str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_3: expected ndim=3, found ndim=5"
     ]
    }
   ],
   "source": [
    "model = get_model(FRAMES_PER_VIDEO, FRAME_SQUARE_DIM, KEEP_PROB)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# GET BATCHES OR DEFINE GENERATOR\n",
    "\n",
    "# Train the model on the new video footage.\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
