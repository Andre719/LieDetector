{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, TimeDistributed, LSTM, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import pylab\n",
    "from PIL import Image\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VIDEO_FOLDER = (os.getcwd() + '/videos/Clips')\n",
    "BATCH_SIZE = 32\n",
    "FRAME_SQUARE_DIM = 178\n",
    "FRAMES_PER_VIDEO = 30\n",
    "KEEP_PROB = 0.7\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_and_crop(frame, square_dim):\n",
    "    # get aspect ratio\n",
    "    aspect = frame.size[0]/frame.size[1]\n",
    "    \n",
    "    # resize to 178 on shortest side and keep original aspect ratio\n",
    "    frame = frame.resize((int(square_dim*aspect), square_dim))\n",
    "    \n",
    "    # crop 178 square from center\n",
    "    half_the_width = frame.size[0] / 2\n",
    "    half_the_height = frame.size[1] / 2\n",
    "    frame = frame.crop(\n",
    "        (\n",
    "            half_the_width - (square_dim/2),\n",
    "            half_the_height - (square_dim/2),\n",
    "            half_the_width + (square_dim/2),\n",
    "            half_the_height + (square_dim/2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frames_from_videos(folder, frames_per_video, frame_square_dim):\n",
    "    \n",
    "    # get one video at a time in the folder\n",
    "    for video_file in os.listdir(folder):\n",
    "        \n",
    "        if video_file not in ['Frames']:\n",
    "            video = (folder + '/' + video_file)\n",
    "            video = imageio.get_reader(video,  'ffmpeg')\n",
    "\n",
    "            # get 30 evenly spaced frames per video\n",
    "            step = video.get_meta_data()['nframes'] / frames_per_video\n",
    "            frames_to_get = range(1, video.get_meta_data()['nframes'], int(step))\n",
    "            frames = []\n",
    "            for i in frames_to_get:\n",
    "                frames.append(i)\n",
    "\n",
    "            # only get first 30 frames if there are 31\n",
    "            frames = frames[:30]\n",
    "\n",
    "            # Resize, crop, and save each frame in the Frames folder\n",
    "            ## ex: (os.getcwd + '/videos/Clips/Truthful/Frames') for Truth videos\n",
    "            for frame in frames:\n",
    "                this_frame = video.get_data(frame)\n",
    "                imageio.imwrite(\"this_frame.jpg\", this_frame)\n",
    "                this_frame = Image.open(\"this_frame.jpg\")\n",
    "                this_frame = resize_and_crop(this_frame, frame_square_dim)\n",
    "                this_frame.save((folder + '/Frames/' + video_file + '_0' + str(frame) + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(folder, frames_per_video):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for vid_type in os.listdir(folder):\n",
    "        if not vid_type.startswith('.'):\n",
    "            if vid_type in ['Deceptive']:\n",
    "                label = 'Deceptive'\n",
    "            else:\n",
    "                label = 'Truthful'\n",
    "            \n",
    "            video_tensor = []\n",
    "            frame_counter = 1\n",
    "            frame_files = os.listdir(folder + '/' + vid_type + '/Frames')\n",
    "            for frame_file_iter in range(len(frame_files)):\n",
    "                if frame_file_iter == 0:\n",
    "                    continue\n",
    "                \n",
    "                frame = (folder + '/' + vid_type + '/Frames/' + frame_files[frame_file_iter])\n",
    "\n",
    "                frame = Image.open(frame)\n",
    "\n",
    "                frame_tensor = np.asarray(frame.convert('RGB'))\n",
    "                \n",
    "                video_tensor.append(frame_tensor)\n",
    "                \n",
    "                if frame_counter == frames_per_video:\n",
    "                    X.append(video_tensor)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    video_tensor = []\n",
    "                    frame_counter = 0\n",
    "                    \n",
    "                frame_counter += 1\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare video clips into a resized and cropped series of frames for each video\n",
    "get_frames_from_videos(VIDEO_FOLDER, FRAMES_PER_VIDEO, FRAME_SQUARE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get video tensors ready for network input\n",
    "X, y = get_data(VIDEO_FOLDER, FRAMES_PER_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NEXT IS TO PUT EVERYTHING ON AWS\n",
    "# TRANSFER VIDEO CLIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lw2134/Desktop/DataSci/LieDetector/videos/Clips/Test'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder = (os.getcwd() + '/videos/Clips/Test')\n",
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trial_lie_007.mp4_01.jpg'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(test_folder + '/Frames/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(frames_per_video, frame_square_dim, keep_prob):\n",
    "    # Video file placeholder. Shape = (# of frames, frame-width, frame-length, # of frame-channels (i.e. rgb))\n",
    "    video = Input(shape=(frames_per_video, frame_square_dim, frame_square_dim, 3))\n",
    "\n",
    "    # TRANSFER LEARNING LAYER\n",
    "    # Initialize CNN with weights from InceptionV3 trained on Imagenet.\n",
    "    IncV3 = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # TIME DISTRIBUTION LAYER\n",
    "    # Run each frame through an InceptionV3 CNN layer.\n",
    "    encoded_frames = TimeDistributed(IncV3)(video)\n",
    "\n",
    "    # LSTM LAYER\n",
    "    # Run each frames CNN output through the LSTM layer.\n",
    "    encoded_vid = LSTM(256)(encoded_frames)\n",
    "\n",
    "    # ADDITIONAL LAYERS TO TRAIN NEW CLASSES from our new video footage.\n",
    "    # Add a fully-connected layer with a dropout before predictions.\n",
    "    x = Dense(1024, activation='relu')(encoded_vid)\n",
    "    x = Dropout(keep_prob)(x)\n",
    "\n",
    "    # Add a logistic layer with 2 new classes - \"Lying\" and \"Truth\".\n",
    "    predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    # Throw it all into a Model object.\n",
    "    model = Model(input=IncV3.input, output=predictions)\n",
    "\n",
    "    # Freeze convolutional InceptionV3 layers because we want to start with the it's pre-trained weights.\n",
    "    # This is the \"learning\" that's being \"transferred\".\n",
    "    for layer in IncV3.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET BATCHES OR DEFINE GENERATOR\n",
    "\n",
    "# Train the model on the new video footage.\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
